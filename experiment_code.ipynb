{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "_A_4II-zq-9u",
      "metadata": {
        "id": "_A_4II-zq-9u"
      },
      "source": [
        "## Hardware information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7xGASvs3jrp-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xGASvs3jrp-",
        "outputId": "3ec96643-5e1c-44f0-988e-6660fe9078bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo | grep 'model name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7RwXa9i7yvnq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RwXa9i7yvnq",
        "outputId": "6e8a088a-45ab-4052-c833-c08ce5f9e183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu cores\t: 1\n",
            "cpu cores\t: 1\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo | grep 'cpu cores'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mcq2-ZDQyhu6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcq2-ZDQyhu6",
        "outputId": "0243620a-4836-4088-dafa-7501f1b546ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 1485.873\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n",
            "cpu MHz\t\t: 3000.000\r\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/cpuinfo | grep 'cpu MHz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1SCMe2tzzKC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1SCMe2tzzKC",
        "outputId": "423794e2-6094-4b9e-9853-d17c43d5b4d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Architecture:                       x86_64\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Architecture'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5pGWla8wz6uJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pGWla8wz6uJ",
        "outputId": "9e6834ea-73c4-4cb0-eed1-77ef22329633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thread(s) per core:                 2\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Thread(s) per core'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Cw0C0OiattgM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw0C0OiattgM",
        "outputId": "f3df414d-1b30-49cc-e7b5-83a16c0449c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Core(s) per socket:                 4\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Core(s) per socket'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LFki5RGa0SER",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFki5RGa0SER",
        "outputId": "a965d32e-9f64-45a4-ffbc-ad8eae7325e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Socket(s):                          1\r\n"
          ]
        }
      ],
      "source": [
        "!lscpu | grep 'Socket(s)'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44b9x-fE0kuR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44b9x-fE0kuR",
        "outputId": "301fe943-a11e-4309-b07d-60c0fa77d633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MemTotal:       62745496 kB\r\n"
          ]
        }
      ],
      "source": [
        "!cat /proc/meminfo | grep 'MemTotal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ht1hzoWljsVf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ht1hzoWljsVf",
        "outputId": "9eab50fd-e605-4037-8435-8044e21db8cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: Tesla V100-SXM2-16GB (UUID: GPU-b42ad1e9-bc98-7b0f-288a-a11837d8d0ff)\r\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0837de7",
      "metadata": {
        "id": "a0837de7"
      },
      "source": [
        "## Install requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WfhbazC2G05s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfhbazC2G05s",
        "outputId": "a5fbf070-a981-4064-d0ae-42e4f2990bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 5, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 10, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 29, in <module>\n",
            "    from pip._internal.utils.misc import ensure_dir\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 43, in <module>\n",
            "    from pip._internal.exceptions import CommandError, ExternallyManagedEnvironment\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/exceptions.py\", line 18, in <module>\n",
            "    from pip._vendor.requests.models import Request, Response\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/__init__.py\", line 162, in <module>\n",
            "    from .api import delete, get, head, options, patch, post, put, request\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/api.py\", line 11, in <module>\n",
            "    from . import sessions\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/sessions.py\", line 15, in <module>\n",
            "    from .adapters import HTTPAdapter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/adapters.py\", line 45, in <module>\n",
            "    from .models import Response\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/requests/models.py\", line 13, in <module>\n",
            "    import encodings.idna  # noqa: F401\n",
            "  File \"/usr/lib/python3.10/encodings/idna.py\", line 290, in <module>\n",
            "    class StreamWriter(Codec,codecs.StreamWriter):\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting emoji\n",
            "  Using cached emoji-2.11.0-py2.py3-none-any.whl (433 kB)\n",
            "Collecting preprocessor\n",
            "  Using cached preprocessor-1.1.3.tar.gz (4.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting git+https://github.com/huggingface/accelerate\n",
            "  Cloning https://github.com/huggingface/accelerate to /tmp/pip-req-build-0dp2sg59\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate /tmp/pip-req-build-0dp2sg59\n",
            "  Resolved https://github.com/huggingface/accelerate to commit d9a1b8f97504efad8055693fd2311aa5199791ca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `pip install() --upgrade transformers'\n"
          ]
        }
      ],
      "source": [
        "!pip install upgrade tensorflow\n",
        "!pip install -r requirements.txt\n",
        "!pip install emoji preprocessor sentence_transformers eli5 captum transformers_interpret evaluate transformers[torch] tensorflow\n",
        "!pip install git+https://github.com/huggingface/accelerate\n",
        "!pip install() --upgrade transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Mw0oazPkrgOJ",
      "metadata": {
        "id": "Mw0oazPkrgOJ"
      },
      "source": [
        "# Imports and function definitions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# General purpose\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Modeling\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "torch.set_flush_denormal(True)\n",
        "from transformers import (\n",
        "    BertForSequenceClassification,\n",
        "    AdamW,\n",
        "    BertTokenizer,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "# Hugging Face Dataset\n",
        "from datasets import Dataset\n",
        "\n",
        "# Model performance evaluation\n",
        "import evaluate\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    classification_report,\n",
        "    confusion_matrix\n",
        ")\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Ignore warnings\n",
        "import traceback\n",
        "import warnings\n",
        "\n",
        "# Others\n",
        "import os\n",
        "from sklearn.utils import check_random_state"
      ],
      "metadata": {
        "id": "P8gGrvdODJvN"
      },
      "id": "P8gGrvdODJvN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "# Create a set of stop words\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "d02SkCGgDfV7"
      },
      "id": "d02SkCGgDfV7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d7e776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d7e776",
        "outputId": "ff7f0cb8-411e-44e6-a36f-354aae7bdce3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "class BertClassifier:\n",
        "    \"\"\"\n",
        "    BERT-based text classifier for sequence classification tasks.\n",
        "\n",
        "    This class provides functionality to train, evaluate, and use a BERT\n",
        "    model for text classification tasks. It encapsulates the BERT model\n",
        "    initialization, tokenization, training, evaluation, and prediction\n",
        "    processes.\n",
        "\n",
        "    Methods:\n",
        "        __compute_metrics: Computes evaluation metrics.\n",
        "        compute_loss: Computes the loss using Cross Entropy Loss.\n",
        "        fit: Fine-tune the BERT model using the provided training data.\n",
        "        predict: Make predictions on input text data using the trained model.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, training_args, id2label):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        - training_args (TrainingArguments): Training argumentsfor\n",
        "          fine-tuning BERT.\n",
        "        - id2label (dict): Dictionary mapping label IDs to their corresponding\n",
        "          labels.\n",
        "        \"\"\"\n",
        "        self.model = BertForSequenceClassification.from_pretrained(\n",
        "            'bert-base-uncased',\n",
        "            num_labels=17,\n",
        "            id2label=id2label\n",
        "        )\n",
        "        self.device = torch.device(\n",
        "            'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        )\n",
        "        self.model.to(self.device)\n",
        "        self.optimizer = AdamW(self.model.parameters(), lr=2e-5)\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.training_args = training_args\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=None,\n",
        "            eval_dataset=None,\n",
        "            compute_metrics=None\n",
        "        )\n",
        "\n",
        "    def __compute_metrics(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes evaluation metrics.\n",
        "\n",
        "        This method computes evaluation metrics such as accuracy, precision,\n",
        "        recall, and F1-score based on the provided logits and labels.\n",
        "\n",
        "        Parameters:\n",
        "        - eval_pred (tuple): A tuple containing logits and labels.\n",
        "\n",
        "        Return:\n",
        "            dict: A dictionary containing the evaluation metrics including:\n",
        "                - 'accuracy': Accuracy score\n",
        "                - 'precision': Precision score (macro average)\n",
        "                - 'recall': Recall score (macro average)\n",
        "                - 'f1': F1 score (macro average)\n",
        "        \"\"\"\n",
        "        logits, labels = eval_pred\n",
        "        # probabilities = tf.nn.softmax(logits)\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        results = {\n",
        "            'accuracy': accuracy_score(labels, predictions),\n",
        "            'precision': precision_score(\n",
        "                labels,\n",
        "                predictions,\n",
        "                average='macro',\n",
        "                zero_division=0\n",
        "            ),\n",
        "            'recall': recall_score(\n",
        "                labels,\n",
        "                predictions,\n",
        "                average='macro',\n",
        "                zero_division=0\n",
        "            ),\n",
        "            'f1': f1_score(\n",
        "                labels,\n",
        "                predictions,\n",
        "                average='macro',\n",
        "                zero_division=0\n",
        "            )\n",
        "        }\n",
        "        return results\n",
        "\n",
        "    def compute_loss(self, eval_pred):\n",
        "        \"\"\"\n",
        "        Computes the loss using Cross Entropy Loss.\n",
        "\n",
        "        This method calculates the loss using the Cross Entropy Loss function\n",
        "        based on the provided logits and labels.\n",
        "\n",
        "        Parameters:\n",
        "        - eval_pred (tuple): A tuple containing logits and labels.\n",
        "\n",
        "        Return:\n",
        "            torch.Tensor: The computed loss value.\n",
        "        \"\"\"\n",
        "        logits, labels = eval_pred\n",
        "        loss_fn = nn.CrossEntropyLoss()\n",
        "        loss = loss_fn(logits, labels)\n",
        "        return loss\n",
        "\n",
        "    def fit(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Fine-tunes the BERT model using the provided training data.\n",
        "\n",
        "        This method fine-tunes the BERT model using the provided training data\n",
        "        and evaluates its performance on the provided testing data.\n",
        "\n",
        "        Parameters:\n",
        "        - X_train (list): A list of input text data for training.\n",
        "        - y_train (list): A list of corresponding labels for training.\n",
        "        - X_test (list): A list of input text data for testing.\n",
        "        - y_test (list): A list of corresponding labels for testing.\n",
        "        \"\"\"\n",
        "        train_tokens = self.tokenizer(\n",
        "            X_train,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(self.device)\n",
        "        train_tokens['labels'] = torch.tensor(y_train).to(self.device)\n",
        "        train_dataset = Dataset.from_dict(\n",
        "            {k: v for k, v in train_tokens.items()}\n",
        "        )\n",
        "\n",
        "        test_tokens = self.tokenizer(\n",
        "            X_test,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        test_tokens.to(self.device)\n",
        "        test_tokens['labels'] = torch.tensor(y_test).to(self.device)\n",
        "        test_dataset = Dataset.from_dict(\n",
        "            {k: v for k, v in test_tokens.items()}\n",
        "        )\n",
        "\n",
        "        self.trainer = Trainer(\n",
        "            model=self.model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=test_dataset,\n",
        "            compute_metrics=self.__compute_metrics\n",
        "        )\n",
        "        self.trainer.train()\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Makes predictions on input text data using the trained model.\n",
        "\n",
        "        This method takes input text data, tokenizes it, and makes predictions\n",
        "        using the trained BERT model.\n",
        "\n",
        "        Parameters:\n",
        "        - X (list): A list of input text data.\n",
        "\n",
        "        Returns:\n",
        "            numpy.ndarray: An array of predicted labels.\n",
        "        \"\"\"\n",
        "        test_tokens = self.tokenizer(\n",
        "            X,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        test_tokens.to(self.device)\n",
        "        test_dataset = Dataset.from_dict(\n",
        "            {k: v for k, v in test_tokens.items()}\n",
        "        )\n",
        "        self.trainer.compute_metrics = self.__compute_metrics\n",
        "        self.trainer.eval_dataset = test_dataset\n",
        "\n",
        "        predictions = self.trainer.predict(test_dataset)\n",
        "        return predictions.predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(\n",
        "    true_labels,\n",
        "    pred_labels,\n",
        "    figsize=(20, 10),\n",
        "    save=False,\n",
        "    save_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots a confusion matrix.\n",
        "\n",
        "    Parameters:\n",
        "    - true_labels: Actual labels\n",
        "    - pred_labels: Predicted labels\n",
        "    - figsize: Size of the figure (default is (15, 10))\n",
        "    \"\"\"\n",
        "    # Get unique labels\n",
        "    labels = np.unique(true_labels)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(true_labels, pred_labels)\n",
        "\n",
        "    # Convert to DataFrame for easier visualization\n",
        "    cm_df = pd.DataFrame(cm, index=labels + 1, columns=labels + 1)\n",
        "\n",
        "    # Create a heatmap using seaborn\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "\n",
        "    # Save the plot if save is True\n",
        "    if save:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "RVEOOe8pCEhW"
      },
      "id": "RVEOOe8pCEhW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_classification_report(\n",
        "    df_report,\n",
        "    train_data,\n",
        "    figsize=(15, 10),\n",
        "    save=False,\n",
        "    save_path=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Plots a classification report.\n",
        "\n",
        "    Parameters:\n",
        "    - df_report: DataFrame containing the classification report\n",
        "    - train_data: DataFrame containing the training data\n",
        "    - figsize: Size of the figure (default is (15, 10))\n",
        "    \"\"\"\n",
        "    # Calculate the frequencies\n",
        "    frequencies = train_data['label'].value_counts()\n",
        "\n",
        "    # Create the xticks labels with frequencies\n",
        "    xticks = (\n",
        "        [\n",
        "            f'{label+1} ({frequencies[label]})'\n",
        "            for label in range(0, 17)\n",
        "        ]\n",
        "        + ['macro avg', 'weighted avg']\n",
        "    )\n",
        "\n",
        "    df_report.index = df_report.index.astype(str)\n",
        "\n",
        "    # Plot the classification report\n",
        "    df_report.plot(\n",
        "        kind='bar',\n",
        "        ylim=(0,1),\n",
        "        rot=90,\n",
        "        title='Classification Report',\n",
        "        figsize=figsize\n",
        "    )\n",
        "\n",
        "    # Set the xticks\n",
        "    _ = plt.xticks(range(len(xticks)-1), xticks)\n",
        "\n",
        "    # Save the plot if save is True\n",
        "    if save:\n",
        "        plt.savefig(save_path)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-zDRu-M_CI8c"
      },
      "id": "-zDRu-M_CI8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(x):\n",
        "    \"\"\"\n",
        "    Computes the softmax function for an input array.\n",
        "\n",
        "    Parameters:\n",
        "    - x (numpy.ndarray): Input array of real numbers.\n",
        "\n",
        "    Return:\n",
        "        numpy.ndarray: An array of softmax probabilities corresponding to\n",
        "        each element in the input array 'x'.\n",
        "    \"\"\"\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum()"
      ],
      "metadata": {
        "id": "DWClzk_RCMuT"
      },
      "id": "DWClzk_RCMuT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_training_args():\n",
        "    \"\"\"\n",
        "    Generates training arguments and label mappings for a BERT-based sequence classification model.\n",
        "\n",
        "    Return:\n",
        "        tuple: A tuple containing two elements:\n",
        "            - training_args (TrainingArguments): Training arguments for the\n",
        "              Trainer object.\n",
        "            - id2label (dict): Dictionary mapping label indices to Sustainable\n",
        "              Development Goals (SDGs).\n",
        "    \"\"\"\n",
        "    # Set up model parameters\n",
        "    # Define the 17 SDGs\n",
        "    sdgs = [\n",
        "        'No Poverty',\n",
        "        'Zero Hunger',\n",
        "        'Good Health and Well-being',\n",
        "        'Quality Education',\n",
        "        'Gender Equality',\n",
        "        'Clean Water and Sanitation',\n",
        "        'Affordable and Clean Energy',\n",
        "        'Decent Work and Economic Growth',\n",
        "        'Industry, Innovation, and Infrastructure',\n",
        "        'Reduced Inequality',\n",
        "        'Sustainable Cities and Communities',\n",
        "        'Responsible Consumption and Production',\n",
        "        'Climate Action',\n",
        "        'Life Below Water',\n",
        "        'Life on Land',\n",
        "        'Peace, Justice, and Strong Institutions',\n",
        "        'Partnerships for the Goals\n",
        "    ]\n",
        "\n",
        "    # Create a dictionary to map the SDGs to their respective IDs\n",
        "    id2label = {}\n",
        "\n",
        "    for i, sgd in enumerate(sdgs):\n",
        "        id2label[i] = sgd\n",
        "\n",
        "    # Set up the training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=(\n",
        "            './training_logs/bert-base-uncased-stratified-simplified/'\n",
        "        ),\n",
        "        logging_dir=(\n",
        "            './training_logs/bert-base-uncased-stratified-simplified/logs/'\n",
        "        ),\n",
        "        logging_strategy='epoch',\n",
        "        logging_steps=100,\n",
        "        per_device_train_batch_size=4,\n",
        "        per_device_eval_batch_size=4,\n",
        "        learning_rate=5e-6,\n",
        "        save_strategy='epoch',\n",
        "        save_steps=100,\n",
        "        evaluation_strategy='epoch',\n",
        "        eval_steps=100,\n",
        "        load_best_model_at_end=True,\n",
        "        num_train_epochs=10,\n",
        "    )\n",
        "\n",
        "    return training_args, id2label"
      ],
      "metadata": {
        "id": "-x-DLtK6CPe9"
      },
      "id": "-x-DLtK6CPe9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "5b55cde2",
      "metadata": {
        "id": "5b55cde2"
      },
      "source": [
        "# **Model training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d57e48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "51d57e48",
        "outputId": "803ead36-daf6-4d4b-d32c-febb54462026"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_abstract_text</th>\n",
              "      <th>processed_abstract_text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>label</th>\n",
              "      <th>label_count</th>\n",
              "      <th>character_count</th>\n",
              "      <th>word_count</th>\n",
              "      <th>token_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n                  In this manuscript we repo...</td>\n",
              "      <td>manuscript report facile synthesis route elect...</td>\n",
              "      <td>tensor([[  101,  8356,  3189,  6904,  6895,  2...</td>\n",
              "      <td>6</td>\n",
              "      <td>1307</td>\n",
              "      <td>2550</td>\n",
              "      <td>286</td>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n                  \\n                     Cys...</td>\n",
              "      <td>cystoseira sargassaceae genus marine brown alg...</td>\n",
              "      <td>tensor([[  101, 22330, 16033, 20240,  2527, 18...</td>\n",
              "      <td>2</td>\n",
              "      <td>7772</td>\n",
              "      <td>1169</td>\n",
              "      <td>143</td>\n",
              "      <td>155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\\n                  Colorectal cancer is one o...</td>\n",
              "      <td>colorectal cancer one common types cancer acco...</td>\n",
              "      <td>tensor([[  101,  3609, 22471,  2389,  4456,  2...</td>\n",
              "      <td>2</td>\n",
              "      <td>7772</td>\n",
              "      <td>2254</td>\n",
              "      <td>309</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\\n                  Aims\\n                  Ca...</td>\n",
              "      <td>aims cardiac arrhythmias one important remote ...</td>\n",
              "      <td>tensor([[  101,  8704, 15050, 12098, 25032, 22...</td>\n",
              "      <td>2</td>\n",
              "      <td>7772</td>\n",
              "      <td>2561</td>\n",
              "      <td>296</td>\n",
              "      <td>294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\n                  Hesperidin is an abundant ...</td>\n",
              "      <td>hesperidin abundant flavanone cheap byproduct ...</td>\n",
              "      <td>tensor([[  101,  2002, 17668, 28173,  2078, 12...</td>\n",
              "      <td>2</td>\n",
              "      <td>7772</td>\n",
              "      <td>1564</td>\n",
              "      <td>224</td>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              original_abstract_text  \\\n",
              "0  \\n                  In this manuscript we repo...   \n",
              "1  \\n                  \\n                     Cys...   \n",
              "2  \\n                  Colorectal cancer is one o...   \n",
              "3  \\n                  Aims\\n                  Ca...   \n",
              "4  \\n                  Hesperidin is an abundant ...   \n",
              "\n",
              "                             processed_abstract_text  \\\n",
              "0  manuscript report facile synthesis route elect...   \n",
              "1  cystoseira sargassaceae genus marine brown alg...   \n",
              "2  colorectal cancer one common types cancer acco...   \n",
              "3  aims cardiac arrhythmias one important remote ...   \n",
              "4  hesperidin abundant flavanone cheap byproduct ...   \n",
              "\n",
              "                                              tokens  label  label_count  \\\n",
              "0  tensor([[  101,  8356,  3189,  6904,  6895,  2...      6         1307   \n",
              "1  tensor([[  101, 22330, 16033, 20240,  2527, 18...      2         7772   \n",
              "2  tensor([[  101,  3609, 22471,  2389,  4456,  2...      2         7772   \n",
              "3  tensor([[  101,  8704, 15050, 12098, 25032, 22...      2         7772   \n",
              "4  tensor([[  101,  2002, 17668, 28173,  2078, 12...      2         7772   \n",
              "\n",
              "   character_count  word_count  token_count  \n",
              "0             2550         286          321  \n",
              "1             1169         143          155  \n",
              "2             2254         309          243  \n",
              "3             2561         296          294  \n",
              "4             1564         224          223  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Meaning of columns:\n",
        "\n",
        "original_absract_text: The unprocessed abstract text\n",
        "preprocessed_abstract_text: The preprocessed abstract text\n",
        "tokens: The tokenized abstract text after preprocessing\n",
        "label_count: The number of labels\n",
        "label: The SDG label\n",
        "character_count: The number of characters in the unprocessed abstract text\n",
        "word_count: The number of words in the unprocessed abstract text\n",
        "token_count: The number of tokens in the tokenized abstract text\n",
        "\"\"\"\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('original_and_preprocessed.csv', sep=';', encoding='utf-8')\n",
        "df['label'] = df['label'] - 1 # Adjust labels to start from 0 to 16 because the model expects labels from 0 to 16\n",
        "df.drop_duplicates(inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a46659a",
      "metadata": {
        "id": "2a46659a",
        "outputId": "8249b70f-92cf-4e36-9c1f-b3ccda9cc1a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13789, 8)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verify the shape of the data\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38b2e0e7",
      "metadata": {
        "id": "38b2e0e7"
      },
      "outputs": [],
      "source": [
        "# Initialize training arguments\n",
        "set_training_args()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bbb794e",
      "metadata": {
        "id": "4bbb794e"
      },
      "source": [
        "## **30x train-test run**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8cfba55",
      "metadata": {
        "scrolled": true,
        "id": "e8cfba55",
        "outputId": "331021ab-428b-43ee-a093-56c85ca67f86"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r\n",
            "Run:   0%|          | 0/30 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are the counts equal? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1637' max='27580' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 1637/27580 03:36 < 57:23, 7.53 it/s, Epoch 0.59/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 30x train-test run\n",
        "\n",
        "# Ignore warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data resetting the index\n",
        "X = df['processed_abstract_text'].reset_index(drop=True)\n",
        "y = df['label'].reset_index(drop=True)\n",
        "\n",
        "# Will be use to construct a confusion matrix composed of the means of the confusion matrices of each run\n",
        "total_cm = np.zeros((17, 17))\n",
        "# List to store the classification reports of each run to create a final report with the mean\n",
        "classification_reports = []\n",
        "# Get the unique classes in the entire dataset, will be needed to check if all labels are represented in both training and testing sets\n",
        "unique_labels = np.unique(y)\n",
        "\n",
        "equal_counts_list = [] # To check if the\n",
        "\n",
        "# This code implements a small checkpoint system to avoid losing progress in case of an error\n",
        "# It will save the results of each run in a separate file, and the iteration number in a checkpoint file\n",
        "if os.path.exists('checkpoints/checkpoint.txt'): # Check if the checkpoint file exists\n",
        "    with open('checkpoints/checkpoint.txt', 'r') as f: # If it does, read the iteration number from it\n",
        "        start_iter = int(f.read())\n",
        "else:\n",
        "    start_iter = 0 # If it doesn't, start from 0\n",
        "\n",
        "# This for loop will run the model 30 times, each time with a different random state\n",
        "for i in tqdm(range(start_iter, 30), desc='Run', leave=True):\n",
        "    train_index, test_index = 0, 0 # initialize indices\n",
        "    X_train, X_test, y_train, y_test = np.array([]), np.array([]), np.array([]), np.array([]) # initiallize empty numpy arrays\n",
        "\n",
        "    try:\n",
        "        # Check if the report for this iteration already exists\n",
        "        if os.path.exists(f'checkpoints/report_{i}.csv'):\n",
        "            continue # If it does, skip this iteration\n",
        "\n",
        "        report_df = pd.DataFrame() # Initialize the report DataFrame\n",
        "\n",
        "        # Stratified shuffled train-test-split\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=i, stratify=y, shuffle=True)\n",
        "\n",
        "        # Get unique labels in y_test and y\n",
        "        unique_test_labels = np.unique(y_test)\n",
        "\n",
        "        # Because this is an unbalanced data set there might be some train-test-split where not all labels will be represented in both sets\n",
        "        # The next few lines will make sure at least 1 sample from each label is represented in the test set\n",
        "\n",
        "        if set(unique_test_labels) != set(unique_labels): # Check if not all labels are represented in the test set\n",
        "            missing_labels = set(unique_labels) - set(unique_test_labels) # Get the missing labels\n",
        "\n",
        "            # For each missing label, add samples from the training set to the test set\n",
        "            for missing_label in missing_labels:\n",
        "\n",
        "                # Collect the indices of the samples to be moved\n",
        "                missing_label_indices = y_train[y_train == missing_label].index.tolist()\n",
        "                # Get the index of the first occurence of the missing label\n",
        "                missing_label_index = missing_label_indices[0]\n",
        "\n",
        "                # Add these samples to the test set\n",
        "                X_test = pd.concat([X_test, X_train.loc[[missing_label_index]]], axis=0)\n",
        "                y_test = pd.concat([y_test, y_train.loc[[missing_label_index]]], axis=0)\n",
        "\n",
        "                # Remove these samples from the training set\n",
        "                X_train = X_train.drop(missing_label_index)\n",
        "                y_train = y_train.drop(missing_label_index)\n",
        "\n",
        "        # Initialize and fit the model\n",
        "        bert_classifier = BertClassifier(training_args, id2label)\n",
        "        bert_classifier.fit(X_train.tolist(), # The train and test sets need to be converted to lists\n",
        "                            y_train.tolist(),\n",
        "                            X_test.tolist(), # The test dataset is for evaluation only, the model will never see this set when training\n",
        "                            y_test.tolist()\n",
        "                            )\n",
        "\n",
        "        # Make predictions\n",
        "        pred_logits = bert_classifier.predict(X_test.tolist())\n",
        "        y_pred = np.argmax(pred_logits, axis=1) # Get the predicted labels from logits\n",
        "\n",
        "        # Get the classification report\n",
        "        report_dict = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
        "        # Convert the report to a DataFrame\n",
        "        report_df = pd.DataFrame(report_dict)\n",
        "        # Append the report to the list of reports, so later on we can calculate the mean and create a final report\n",
        "        classification_reports.append(report_df)\n",
        "\n",
        "        # Update the total confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)\n",
        "        total_cm += cm\n",
        "\n",
        "        # Used by the checkpoint system\n",
        "        # Save the results after each run\n",
        "        with open(f'checkpoints/report_{i}.csv', 'w') as f: # Save the current classification report\n",
        "            print(f'Saving report {i}...')\n",
        "            report_df.to_csv(f, sep=';', index_label='Metrics')\n",
        "        with open(f'checkpoints/total_cm_{i}.csv', 'w') as f: # Save the current confusion matrix\n",
        "            print(f'Saving confusion matrix {i}...')\n",
        "            pd.DataFrame(total_cm).to_csv(f, sep=';', index=False)\n",
        "        with open(f'results/pred_logits_{i}.csv', 'w') as f: # Save the prediction logits\n",
        "            print(f'Saving prediction logits {i}...')\n",
        "            pd.DataFrame(pred_logits).to_csv(f, sep=';', index=False)\n",
        "        # Save the current model weights so we can select the model weights with\n",
        "        # the best performance at the end of the experimetn\n",
        "        with open(f'model/model_state_{i}.pt', 'wb') as f:\n",
        "            print(f'Saving model state {i}...')\n",
        "            torch.save(bert_classifier.model.state_dict(), f)\n",
        "        # Save the current iteration number to the checkpoint file\n",
        "        with open('checkpoints/checkpoint.txt', 'w') as f:\n",
        "            print(f'Saving checkpoint {i}...')\n",
        "            f.write(str(i))\n",
        "\n",
        "    except Exception as e: # If an error occurs, print the error and the traceback\n",
        "        print(f'Error in run {i}: {e}')\n",
        "        traceback.print_exc()\n",
        "\n",
        "# This is the end of the 30x runs\n",
        "# Now, concatenate the reports and calculate the mean\n",
        "all_reports = pd.concat(classification_reports, axis=0)\n",
        "mean_reports = all_reports.groupby(all_reports.index).mean()\n",
        "\n",
        "# Save concatenated reports for backup\n",
        "with open('results/all_reports_backup.csv', 'w') as f:\n",
        "    print('Saving all reports...')\n",
        "    all_reports.to_csv(f, sep=';', index_label='Metrics')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9c7f0da",
      "metadata": {
        "id": "b9c7f0da",
        "outputId": "8862c7e3-c705-421d-fd5e-b42c4cec3a81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving all reports...\n"
          ]
        }
      ],
      "source": [
        "# Calculate the best run to get the best model_state\n",
        "\n",
        "_all_reports = all_reports\n",
        "\n",
        "# Calculate the number of metrics per run\n",
        "total_runs = 30\n",
        "metrics_per_run = len(_all_reports) // total_runs  # replace 'total_runs' with the actual number of runs\n",
        "\n",
        "# Create a range from 0 to the number of rows in _all_reports\n",
        "run_numbers = range(len(_all_reports))\n",
        "\n",
        "# Convert the range to a DataFrame\n",
        "run_numbers_df = pd.DataFrame(run_numbers, columns=['run_number'], index=_all_reports.index)\n",
        "\n",
        "# Divide the run numbers by the number of metrics per run and add 1 to get the run number for each report\n",
        "run_numbers_df['run_number'] = (run_numbers_df['run_number'] // metrics_per_run) + 1\n",
        "\n",
        "# Add the run number column to _all_reports\n",
        "_all_reports = pd.concat([_all_reports, run_numbers_df], axis=1)\n",
        "\n",
        "# Remove the 'support' rows\n",
        "_all_reports = _all_reports.drop('support')\n",
        "\n",
        "# Rename index to metrics\n",
        "_all_reports.index.name = 'metric'\n",
        "\n",
        "# Reset the index to move 'metric' from index to a regular column\n",
        "_all_reports.reset_index(inplace=True)\n",
        "\n",
        "# Get the best run number\n",
        "best_run_number = _all_reports['macro avg'].idxmax()\n",
        "\n",
        "# Save all reports\n",
        "with open('results/all_reports.csv', 'w') as f:\n",
        "    print('Saving all reports...')\n",
        "    _all_reports.to_csv(f, sep=';', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa0ba822",
      "metadata": {
        "id": "aa0ba822",
        "outputId": "62635320-ff80-4f9c-c2e2-328759d9558d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6087</td>\n",
              "      <td>0.9630</td>\n",
              "      <td>0.641415</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.787927</td>\n",
              "      <td>0.889917</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713996</td>\n",
              "      <td>0.442198</td>\n",
              "      <td>0.618922</td>\n",
              "      <td>0.162129</td>\n",
              "      <td>0.451739</td>\n",
              "      <td>0.757418</td>\n",
              "      <td>0.691908</td>\n",
              "      <td>0.346912</td>\n",
              "      <td>0.838568</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>0.524398</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>0.9580</td>\n",
              "      <td>0.650871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.765447</td>\n",
              "      <td>0.872560</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.702552</td>\n",
              "      <td>0.757897</td>\n",
              "      <td>0.669004</td>\n",
              "      <td>0.337308</td>\n",
              "      <td>0.723548</td>\n",
              "      <td>0.744790</td>\n",
              "      <td>0.756536</td>\n",
              "      <td>0.562743</td>\n",
              "      <td>0.822054</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>0.584060</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.9682</td>\n",
              "      <td>0.652083</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818721</td>\n",
              "      <td>0.909195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.732850</td>\n",
              "      <td>0.342857</td>\n",
              "      <td>0.594624</td>\n",
              "      <td>0.118519</td>\n",
              "      <td>0.383810</td>\n",
              "      <td>0.774167</td>\n",
              "      <td>0.642373</td>\n",
              "      <td>0.272727</td>\n",
              "      <td>0.857173</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>0.510940</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1.0</td>\n",
              "      <td>59.0000</td>\n",
              "      <td>1554.0000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>474.000000</td>\n",
              "      <td>0.886094</td>\n",
              "      <td>2759.000000</td>\n",
              "      <td>2759</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1        2          3          4    5          6           7  \\\n",
              "f1-score   0.0   0.6087     0.9630   0.641415  0.0   0.787927    0.889917   \n",
              "precision  0.0   0.6057     0.9580   0.650871  0.0   0.765447    0.872560   \n",
              "recall     0.0   0.6186     0.9682   0.652083  0.0   0.818721    0.909195   \n",
              "support    1.0  59.0000  1554.0000  16.000000  3.0  73.000000  261.000000   \n",
              "\n",
              "             8          9        10         11         12         13  \\\n",
              "f1-score   0.0   0.713996  0.442198   0.618922   0.162129   0.451739   \n",
              "precision  0.0   0.702552  0.757897   0.669004   0.337308   0.723548   \n",
              "recall     0.0   0.732850  0.342857   0.594624   0.118519   0.383810   \n",
              "support    8.0  69.000000  7.000000  31.000000  18.000000  35.000000   \n",
              "\n",
              "                  14         15         16          17  accuracy    macro avg  \\\n",
              "f1-score    0.757418   0.691908   0.346912    0.838568  0.886094     0.524398   \n",
              "precision   0.744790   0.756536   0.562743    0.822054  0.886094     0.584060   \n",
              "recall      0.774167   0.642373   0.272727    0.857173  0.886094     0.510940   \n",
              "support    80.000000  59.000000  11.000000  474.000000  0.886094  2759.000000   \n",
              "\n",
              "           weighted avg  \n",
              "f1-score              1  \n",
              "precision             1  \n",
              "recall                1  \n",
              "support            2759  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Divide total_cm by the number of runs to get the mean confusion matrix\n",
        "mean_cm = total_cm / 30\n",
        "\n",
        "# Sorting mean reports\n",
        "# Separate numeric and non-numeric rows\n",
        "numeric_reports = mean_reports[mean_reports.index.str.isnumeric()]\n",
        "non_numeric_reports = mean_reports[~mean_reports.index.str.isnumeric()]\n",
        "\n",
        "# Convert numeric indices to int and sort\n",
        "numeric_reports.index = numeric_reports.index.astype(int)\n",
        "numeric_reports = numeric_reports.sort_index()\n",
        "\n",
        "# Concatenate the DataFrames back together\n",
        "mean_reports = pd.concat([numeric_reports, non_numeric_reports])\n",
        "\n",
        "# Round the numeric values to 4 decimal places and convert the last column to integers\n",
        "mean_reports[mean_reports.columns[:3]] = mean_reports[mean_reports.columns[:3]].round(4)\n",
        "mean_reports[mean_reports.columns[-1]] = mean_reports[mean_reports.columns[-1]].round().astype(int)\n",
        "\n",
        "# Rename the columns to match the original classification report\n",
        "column_mapping = {str(old): str(old + 1) for old in range(0, 17)}\n",
        "mean_reports = mean_reports.rename(columns=column_mapping)\n",
        "\n",
        "# Finally, save the mean classification report to a CSV file\n",
        "mean_reports.to_csv('results/30x_classification_report.csv', sep=';', index=False)\n",
        "mean_reports # Visualize the mean classification report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a9c405f",
      "metadata": {
        "id": "7a9c405f"
      },
      "source": [
        "# Choosing the best model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72177273",
      "metadata": {
        "id": "72177273",
        "outputId": "8dd43a88-7f18-4538-90a9-fb70e3565532"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>metric</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "      <th>run_number</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.940075</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784615</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.602273</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.810445</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>0.519553</td>\n",
              "      <td>0.865333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.525424</td>\n",
              "      <td>0.969112</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.698630</td>\n",
              "      <td>0.911877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.768116</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.661017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.883966</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>0.431316</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>f1-score</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.568807</td>\n",
              "      <td>0.954373</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.879852</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.675159</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.243902</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.845610</td>\n",
              "      <td>0.880029</td>\n",
              "      <td>0.452825</td>\n",
              "      <td>0.867371</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.672727</td>\n",
              "      <td>0.974526</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.736842</td>\n",
              "      <td>0.902622</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.735294</td>\n",
              "      <td>...</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.806818</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.641845</td>\n",
              "      <td>0.894499</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>recall</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.627119</td>\n",
              "      <td>0.960103</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.767123</td>\n",
              "      <td>0.923372</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.724638</td>\n",
              "      <td>...</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.542857</td>\n",
              "      <td>0.825000</td>\n",
              "      <td>0.593220</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.898734</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.563872</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>f1-score</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.649123</td>\n",
              "      <td>0.967261</td>\n",
              "      <td>0.645161</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.751678</td>\n",
              "      <td>0.912879</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.729927</td>\n",
              "      <td>...</td>\n",
              "      <td>0.580645</td>\n",
              "      <td>0.644068</td>\n",
              "      <td>0.763006</td>\n",
              "      <td>0.673077</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.850299</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.587775</td>\n",
              "      <td>0.893385</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>precision</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.855263</td>\n",
              "      <td>0.871324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.626664</td>\n",
              "      <td>0.900001</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      metric    0         1         2         3    4         5         6    7  \\\n",
              "0  precision  0.0  0.620000  0.940075  0.800000  0.0  0.784615  0.850000  0.0   \n",
              "1     recall  0.0  0.525424  0.969112  0.500000  0.0  0.698630  0.911877  0.0   \n",
              "2   f1-score  0.0  0.568807  0.954373  0.615385  0.0  0.739130  0.879852  0.0   \n",
              "3  precision  0.0  0.672727  0.974526  0.666667  0.0  0.736842  0.902622  0.0   \n",
              "4     recall  0.0  0.627119  0.960103  0.625000  0.0  0.767123  0.923372  0.0   \n",
              "5   f1-score  0.0  0.649123  0.967261  0.645161  0.0  0.751678  0.912879  0.0   \n",
              "6  precision  0.0  0.642857  0.971741  0.684211  0.0  0.855263  0.871324  0.0   \n",
              "\n",
              "          8  ...        11        12        13        14        15        16  \\\n",
              "0  0.602273  ...  0.000000  0.833333  0.787500  0.866667  0.000000  0.810445   \n",
              "1  0.768116  ...  0.000000  0.142857  0.787500  0.661017  0.000000  0.883966   \n",
              "2  0.675159  ...  0.000000  0.243902  0.787500  0.750000  0.000000  0.845610   \n",
              "3  0.735294  ...  0.692308  0.791667  0.709677  0.777778  1.000000  0.806818   \n",
              "4  0.724638  ...  0.500000  0.542857  0.825000  0.593220  0.363636  0.898734   \n",
              "5  0.729927  ...  0.580645  0.644068  0.763006  0.673077  0.533333  0.850299   \n",
              "6  0.750000  ...  0.700000  0.650000  0.758242  0.730159  0.833333  0.862069   \n",
              "\n",
              "   accuracy  macro avg  weighted avg  run_number  \n",
              "0  0.880029   0.519553      0.865333           1  \n",
              "1  0.880029   0.431316      0.880029           1  \n",
              "2  0.880029   0.452825      0.867371           1  \n",
              "3  0.896339   0.641845      0.894499           2  \n",
              "4  0.896339   0.563872      0.896339           2  \n",
              "5  0.896339   0.587775      0.893385           2  \n",
              "6  0.903588   0.626664      0.900001           3  \n",
              "\n",
              "[7 rows x 22 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the csv file that contains the sklearn's classification report for each run\n",
        "all_reports = pd.read_csv('results/all_reports.csv', sep=';')\n",
        "all_reports.head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "864282d7",
      "metadata": {
        "id": "864282d7",
        "outputId": "0403f50b-1006-46f2-ac13-0f50219f0c66"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the per class f1-scores in a boxplot\n",
        "\n",
        "# Filter the DataFrame\n",
        "f1_scores = all_reports[all_reports['metric'] == 'f1-score']\n",
        "\n",
        "# Drop non-numeric columns if any\n",
        "#numeric_columns = f1_scores.select_dtypes(include=[np.number]).columns.tolist()\n",
        "f1_scores = f1_scores[['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16']]\n",
        "\n",
        "# Plot the boxplots\n",
        "plt.figure(figsize=(15, 10))\n",
        "f1_scores.boxplot()\n",
        "plt.title('Per class f1-scores')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7532368",
      "metadata": {
        "id": "a7532368"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean and standard deviation of the f1-scores, precision, and recall\n",
        "f1_scores = all_reports[all_reports['metric'] == 'f1-score']\n",
        "precision_scores = all_reports[all_reports['metric'] == 'precision']\n",
        "recall_scores = all_reports[all_reports['metric'] == 'recall']\n",
        "\n",
        "mean_f1_scores = f1_scores.mean() * 100\n",
        "std_f1_scores = f1_scores.std() * 100\n",
        "\n",
        "mean_precision_scores = precision_scores.mean() * 100\n",
        "std_precision_scores = precision_scores.std()\n",
        "\n",
        "mean_recall_scores = recall_scores.mean() * 100\n",
        "std_recall_scores = recall_scores.std() * 100\n",
        "\n",
        "# Create a summary DataFrame\n",
        "f1_scores_summary = mean_f1_scores.map('{:.2f}'.format) + \" (\" + std_f1_scores.map('{:.2f}'.format) + \")\"\n",
        "precision_scores_summary = mean_precision_scores.map('{:.2f}'.format) + \" (\" + std_precision_scores.map('{:.2f}'.format) + \")\"\n",
        "recall_scores_summary = mean_recall_scores.map('{:.2f}'.format) + \" (\" + std_recall_scores.map('{:.2f}'.format) + \")\"\n",
        "\n",
        "scores_summary = pd.DataFrame({'f1-score': f1_scores_summary,\n",
        "                               'precision': precision_scores_summary,\n",
        "                               'recall': recall_scores_summary})\n",
        "\n",
        "scores_summary.to_csv('results/scores_summary.csv', sep=';', index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "317d276a",
      "metadata": {
        "id": "317d276a",
        "outputId": "e5d9e300-5960-4e77-abad-26c1f275fc1d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identify the index of the model that achieved the highest f1-score\n",
        "all_reports[all_reports['metric'] == 'f1-score']['macro avg'].reset_index(drop=True).idxmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd6b6250",
      "metadata": {
        "id": "cd6b6250"
      },
      "source": [
        "# **Considering an additional class with a threshold:**\n",
        "When the maximum predicted probability is less than 80%, we consider the sample as no related to any Sustainable Development Goal\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8721e59f",
      "metadata": {
        "id": "8721e59f"
      },
      "outputs": [],
      "source": [
        "# Load dataset and adjust labels\n",
        "df = pd.read_csv('original_and_preprocessed.csv', sep=';', encoding='utf-8')\n",
        "df['label'] = df['label'] - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08797ea0",
      "metadata": {
        "id": "08797ea0",
        "outputId": "fc027a32-6cfe-4997-ba99-542dd5a09fa9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(13789, 8)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5597b81c",
      "metadata": {
        "id": "5597b81c",
        "outputId": "a24c3529-2992-4c17-b246-54630ca75228"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Are the counts equal? True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/home/ubuntu/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.971741</td>\n",
              "      <td>0.684211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.855263</td>\n",
              "      <td>0.871324</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>0.758242</td>\n",
              "      <td>0.730159</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.862069</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.626664</td>\n",
              "      <td>0.900001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.610169</td>\n",
              "      <td>0.973616</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.890411</td>\n",
              "      <td>0.908046</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.862500</td>\n",
              "      <td>0.779661</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.843882</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.603239</td>\n",
              "      <td>0.903588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.626087</td>\n",
              "      <td>0.972678</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.872483</td>\n",
              "      <td>0.889306</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.744526</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.677419</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.693333</td>\n",
              "      <td>0.807018</td>\n",
              "      <td>0.754098</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.852878</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>0.608018</td>\n",
              "      <td>0.901015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1.0</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>1554.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>261.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>474.000000</td>\n",
              "      <td>0.903588</td>\n",
              "      <td>2759.000000</td>\n",
              "      <td>2759.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0          1            2          3    4          5           6  \\\n",
              "precision  0.0   0.642857     0.971741   0.684211  0.0   0.855263    0.871324   \n",
              "recall     0.0   0.610169     0.973616   0.812500  0.0   0.890411    0.908046   \n",
              "f1-score   0.0   0.626087     0.972678   0.742857  0.0   0.872483    0.889306   \n",
              "support    1.0  59.000000  1554.000000  16.000000  3.0  73.000000  261.000000   \n",
              "\n",
              "             7          8         9         10         11         12  \\\n",
              "precision  0.0   0.750000  0.666667   0.677419   0.700000   0.650000   \n",
              "recall     0.0   0.739130  0.571429   0.677419   0.388889   0.742857   \n",
              "f1-score   0.0   0.744526  0.615385   0.677419   0.500000   0.693333   \n",
              "support    8.0  69.000000  7.000000  31.000000  18.000000  35.000000   \n",
              "\n",
              "                  13         14         15          16  accuracy    macro avg  \\\n",
              "precision   0.758242   0.730159   0.833333    0.862069  0.903588     0.626664   \n",
              "recall      0.862500   0.779661   0.454545    0.843882  0.903588     0.603239   \n",
              "f1-score    0.807018   0.754098   0.588235    0.852878  0.903588     0.608018   \n",
              "support    80.000000  59.000000  11.000000  474.000000  0.903588  2759.000000   \n",
              "\n",
              "           weighted avg  \n",
              "precision      0.900001  \n",
              "recall         0.903588  \n",
              "f1-score       0.901015  \n",
              "support     2759.000000  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This cell is responsible to find the exact same split that was used by the model with best metrics in the 30x runs\n",
        "\n",
        "# The number of the run with the best metrics to load the respective mode weights\n",
        "run_number = 2\n",
        "\n",
        "X = df['processed_abstract_text'].reset_index(drop=True)\n",
        "y = df['label'].reset_index(drop=True)\n",
        "\n",
        "unique_labels = np.unique(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=run_number, stratify=y, shuffle=True) # The random state is the run number\n",
        "\n",
        "# Get unique labels in y_test and y\n",
        "unique_test_labels = np.unique(y_test)\n",
        "\n",
        "# Check if not all labels are represented in the test set\n",
        "if set(unique_test_labels) != set(unique_labels):\n",
        "    missing_labels = set(unique_labels) - set(unique_test_labels)\n",
        "    # If not, add samples from the training set to the test set\n",
        "    for missing_label in missing_labels:\n",
        "\n",
        "        # Collect the indices of the samples to be moved\n",
        "        missing_label_indices = y_train[y_train == missing_label].index.tolist()\n",
        "        # Get the index of the first occurence of the missing label\n",
        "        missing_label_index = missing_label_indices[0]\n",
        "\n",
        "        # Add these samples to the test set\n",
        "        X_test = pd.concat([X_test, X_train.loc[[missing_label_index]]], axis=0)\n",
        "        y_test = pd.concat([y_test, y_train.loc[[missing_label_index]]], axis=0)\n",
        "\n",
        "        # Remove these samples from the training set\n",
        "        X_train = X_train.drop(missing_label_index)\n",
        "        y_train = y_train.drop(missing_label_index)\n",
        "\n",
        "# Initialize the model\n",
        "bert_classifier = BertClassifier(training_args, id2label)\n",
        "\n",
        "# Load the weights of the model that achieve best metrics\n",
        "weights = torch.load(f'model/model_state_{run_number}.pt')\n",
        "bert_classifier.model.load_state_dict(weights)\n",
        "bert_classifier.model.eval() # Set model to evaluation mode\n",
        "\n",
        "# Make predictions\n",
        "pred_logits = bert_classifier.predict(X_test.to_list())\n",
        "y_pred = np.argmax(pred_logits, axis=1)\n",
        "\n",
        "# Get the classification report, rename the columns and save it to a CSV file\n",
        "_classification_report = pd.DataFrame(classification_report(y_test, y_pred, output_dict=True, zero_division=0))\n",
        "\n",
        "_classification_report.to_csv(f'results/best_classification_report.csv', sep=';', index=False, encoding='utf-8')\n",
        "\n",
        "column_mapping = {str(old): str(old + 1) for old in range(0, 17)}\n",
        "_classification_report = _classification_report.rename(columns=column_mapping)\n",
        "_classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc999635",
      "metadata": {
        "id": "cc999635",
        "outputId": "2737fca2-f16a-482a-fe99-b41b764e7a92"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000008</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000019</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000028</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.000053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000323</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>0.000213</td>\n",
              "      <td>0.000416</td>\n",
              "      <td>0.000592</td>\n",
              "      <td>0.000204</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.000255</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>0.000338</td>\n",
              "      <td>0.000448</td>\n",
              "      <td>0.000626</td>\n",
              "      <td>0.991174</td>\n",
              "      <td>0.002447</td>\n",
              "      <td>0.000258</td>\n",
              "      <td>0.001349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000787</td>\n",
              "      <td>0.001338</td>\n",
              "      <td>0.000390</td>\n",
              "      <td>0.000821</td>\n",
              "      <td>0.000901</td>\n",
              "      <td>0.001988</td>\n",
              "      <td>0.000723</td>\n",
              "      <td>0.000939</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>0.001052</td>\n",
              "      <td>0.001870</td>\n",
              "      <td>0.003058</td>\n",
              "      <td>0.953165</td>\n",
              "      <td>0.002166</td>\n",
              "      <td>0.027058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000766</td>\n",
              "      <td>0.005400</td>\n",
              "      <td>0.002651</td>\n",
              "      <td>0.000827</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>0.939815</td>\n",
              "      <td>0.009679</td>\n",
              "      <td>0.000693</td>\n",
              "      <td>0.001023</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>0.002198</td>\n",
              "      <td>0.001893</td>\n",
              "      <td>0.002914</td>\n",
              "      <td>0.002341</td>\n",
              "      <td>0.002761</td>\n",
              "      <td>0.001155</td>\n",
              "      <td>0.024684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000097</td>\n",
              "      <td>0.999503</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2754</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.999754</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2755</th>\n",
              "      <td>0.000312</td>\n",
              "      <td>0.004973</td>\n",
              "      <td>0.098571</td>\n",
              "      <td>0.000439</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000249</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.000598</td>\n",
              "      <td>0.000562</td>\n",
              "      <td>0.000664</td>\n",
              "      <td>0.000442</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>0.000206</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.000881</td>\n",
              "      <td>0.000799</td>\n",
              "      <td>0.889569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2756</th>\n",
              "      <td>0.000038</td>\n",
              "      <td>0.000845</td>\n",
              "      <td>0.997743</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>0.000502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2757</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.999740</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000031</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.000050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2758</th>\n",
              "      <td>0.000007</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.999730</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000014</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2759 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "0     0.000008  0.000030  0.999730  0.000020  0.000019  0.000012  0.000028   \n",
              "1     0.000323  0.000123  0.000386  0.000213  0.000416  0.000592  0.000204   \n",
              "2     0.000787  0.001338  0.000390  0.000821  0.000901  0.001988  0.000723   \n",
              "3     0.000766  0.005400  0.002651  0.000827  0.000885  0.939815  0.009679   \n",
              "4     0.000012  0.000097  0.999503  0.000031  0.000026  0.000011  0.000045   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2754  0.000007  0.000029  0.999754  0.000016  0.000017  0.000012  0.000023   \n",
              "2755  0.000312  0.004973  0.098571  0.000439  0.000664  0.000249  0.000376   \n",
              "2756  0.000038  0.000845  0.997743  0.000081  0.000076  0.000023  0.000135   \n",
              "2757  0.000007  0.000035  0.999740  0.000015  0.000017  0.000010  0.000031   \n",
              "2758  0.000007  0.000033  0.999730  0.000016  0.000017  0.000010  0.000024   \n",
              "\n",
              "            7         8         9         10        11        12        13  \\\n",
              "0     0.000010  0.000014  0.000014  0.000011  0.000009  0.000004  0.000014   \n",
              "1     0.000390  0.000255  0.000458  0.000338  0.000448  0.000626  0.991174   \n",
              "2     0.000939  0.000531  0.000914  0.002300  0.001052  0.001870  0.003058   \n",
              "3     0.000693  0.001023  0.000315  0.002198  0.001893  0.002914  0.002341   \n",
              "4     0.000017  0.000020  0.000020  0.000014  0.000011  0.000005  0.000014   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "2754  0.000009  0.000015  0.000012  0.000011  0.000009  0.000004  0.000014   \n",
              "2755  0.000598  0.000562  0.000664  0.000442  0.000257  0.000206  0.000438   \n",
              "2756  0.000060  0.000072  0.000071  0.000044  0.000036  0.000026  0.000043   \n",
              "2757  0.000010  0.000015  0.000012  0.000010  0.000009  0.000004  0.000014   \n",
              "2758  0.000010  0.000016  0.000012  0.000011  0.000009  0.000004  0.000014   \n",
              "\n",
              "            14        15        16  \n",
              "0     0.000006  0.000018  0.000053  \n",
              "1     0.002447  0.000258  0.001349  \n",
              "2     0.953165  0.002166  0.027058  \n",
              "3     0.002761  0.001155  0.024684  \n",
              "4     0.000010  0.000023  0.000141  \n",
              "...        ...       ...       ...  \n",
              "2754  0.000006  0.000016  0.000046  \n",
              "2755  0.000881  0.000799  0.889569  \n",
              "2756  0.000129  0.000076  0.000502  \n",
              "2757  0.000006  0.000015  0.000050  \n",
              "2758  0.000006  0.000017  0.000064  \n",
              "\n",
              "[2759 rows x 17 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Apply the softmax function to the prediction logits to get the probabilities\n",
        "prediction_probas = pd.DataFrame(pred_logits).apply(softmax, axis=1)\n",
        "prediction_probas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce7de30e",
      "metadata": {
        "id": "ce7de30e"
      },
      "outputs": [],
      "source": [
        "# This cell will filter the samples with a maximum predicted\n",
        "# probability below a certain threshold and create a new classification report\n",
        "\n",
        "# Ensure y_test and prediction_probas have the same indices\n",
        "y_test = y_test.reset_index(drop=True)\n",
        "prediction_probas = prediction_probas.reset_index(drop=True)\n",
        "\n",
        "# Create a dataframe with the max probability value and the corresponding label\n",
        "max_values = pd.DataFrame({\n",
        "    'max_value': prediction_probas.max(axis=1), # maximum probabilities\n",
        "    'prediction': y_pred, # predictions\n",
        "})\n",
        "\n",
        "cap = 0.8\n",
        "number_max_value = len(max_values[max_values['max_value'] < cap])\n",
        "filtered_samples = max_values[max_values['max_value'] < cap]\n",
        "\n",
        "# Get the indices of the samples to exclude\n",
        "exclude_indices = filtered_samples.index\n",
        "predictions = pd.DataFrame(prediction_probas.values.argmax(axis=1))\n",
        "\n",
        "# Create new Series without the excluded samples\n",
        "filtered_pred = predictions.drop(exclude_indices)\n",
        "filtered_true = y_test.drop(exclude_indices)\n",
        "filtered_report = pd.DataFrame(classification_report(filtered_true, filtered_pred, output_dict=True, zero_division=0))\n",
        "\n",
        "# Create a mapping from old column names to new ones\n",
        "column_mapping = {str(old): str(old + 1) for old in range(0, 17)}\n",
        "\n",
        "# Rename the columns\n",
        "filtered_report.rename(columns=column_mapping, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3d1095e",
      "metadata": {
        "scrolled": true,
        "id": "e3d1095e",
        "outputId": "ff1be058-515d-4f8b-d021-8ffb5b11e18b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>macro avg</th>\n",
              "      <th>weighted avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.975974</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.883019</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.810345</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.766667</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.876993</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>0.541940</td>\n",
              "      <td>0.919562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.673077</td>\n",
              "      <td>0.981711</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.924901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.783333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.873418</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>0.533698</td>\n",
              "      <td>0.925560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1-score</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.721649</td>\n",
              "      <td>0.978834</td>\n",
              "      <td>0.827586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.915493</td>\n",
              "      <td>0.903475</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.796610</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.720000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.78125</td>\n",
              "      <td>0.816568</td>\n",
              "      <td>0.792793</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>0.537015</td>\n",
              "      <td>0.922270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>support</th>\n",
              "      <td>1.0</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>1531.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>4.0</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>2.0</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>7.0</td>\n",
              "      <td>32.00000</td>\n",
              "      <td>79.000000</td>\n",
              "      <td>55.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>441.000000</td>\n",
              "      <td>0.92556</td>\n",
              "      <td>2633.000000</td>\n",
              "      <td>2633.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             1          2            3          4    5          6           7  \\\n",
              "precision  0.0   0.777778     0.975974   0.857143  0.0   0.915493    0.883019   \n",
              "recall     0.0   0.673077     0.981711   0.800000  0.0   0.915493    0.924901   \n",
              "f1-score   0.0   0.721649     0.978834   0.827586  0.0   0.915493    0.903475   \n",
              "support    1.0  52.000000  1531.000000  15.000000  2.0  71.000000  253.000000   \n",
              "\n",
              "             8          9   10         11   12        13         14  \\\n",
              "precision  0.0   0.810345  0.0   0.782609  0.0   0.78125   0.766667   \n",
              "recall     0.0   0.783333  0.0   0.666667  0.0   0.78125   0.873418   \n",
              "f1-score   0.0   0.796610  0.0   0.720000  0.0   0.78125   0.816568   \n",
              "support    4.0  60.000000  2.0  27.000000  7.0  32.00000  79.000000   \n",
              "\n",
              "                  15   16          17  accuracy    macro avg  weighted avg  \n",
              "precision   0.785714  0.0    0.876993   0.92556     0.541940      0.919562  \n",
              "recall      0.800000  0.0    0.873016   0.92556     0.533698      0.925560  \n",
              "f1-score    0.792793  0.0    0.875000   0.92556     0.537015      0.922270  \n",
              "support    55.000000  1.0  441.000000   0.92556  2633.000000   2633.000000  "
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Classification report of samples with max probability over 80%\n",
        "filtered_report.to_csv('results/best_classification_report_80.csv', sep=';', index=False, encoding='utf-8')\n",
        "filtered_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bc1fc91",
      "metadata": {
        "id": "0bc1fc91"
      },
      "outputs": [],
      "source": [
        "# Predictions where if the maximum predicted probability is 80% or more the prediction is set to corresponding SDG,\n",
        "# otherwise it is considered as unrelated and set to 0\n",
        "predictions_80 = prediction_probas.idxmax(axis=1).where(prediction_probas.max(axis=1) >= 0.8, 0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "a0837de7",
        "02ffcd69",
        "Mw0oazPkrgOJ",
        "5b55cde2"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}